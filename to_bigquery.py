import time
from datetime import datetime
import socket

import schedule

from decouple import config

# –í–Ω—É—Ç—Ä–µ–Ω–∏–∏–µ –º–æ–¥—É–ª–∏ –ø—Ä–æ–µ–∫—Ç–∞
from api_requests import *
from utils import GetProperties, getparam_yesterday_date
from data_mart_creating import create_data_marts

api_url = config('API_URL')
api_key = config('API_KEY')

log_datetime = datetime.now()

print(f'<{log_datetime}>: –ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ, –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö, API –∑–∞–ø—É—â–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ')

def process_connection(connection):
    # –ó–¥–µ—Å—å –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –ª–æ–≥–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
    data = connection.recv(1024)
    if data:
        print(f"Received data: {data}")
        # –î–æ–±–∞–≤—å—Ç–µ —Å–≤–æ—é –ª–æ–≥–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    connection.close()

def main():
    # –ü–æ–ª—É—á–∏—Ç—å –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è PORT, —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π Dockerfile –∏–ª–∏ –¥—Ä—É–≥–∏–º —Å–ø–æ—Å–æ–±–æ–º
    port = int(config("PORT"))

    # –°–æ–∑–¥–∞—Ç—å —Å–æ–∫–µ—Ç
    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

    # –ü—Ä–∏–≤—è–∑–∞—Ç—å —Å–æ–∫–µ—Ç –∫ –ø–æ—Ä—Ç—É
    sock.bind(("", port))

    # –ó–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä
    sock.listen(5)

    print(f"Server listening on port {port}")

    while True:
        # –ü—Ä–∏–Ω—è—Ç—å –≤—Ö–æ–¥—è—â–µ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        connection, address = sock.accept()

        # –û–±—Ä–∞–±–æ—Ç–∞—Ç—å –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
        process_connection(connection)

if __name__ == "__main__":
    main()

if config('TEST') == 'test':
    print('–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è —É—Å–ø–µ–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã')
else:
    print('–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è')

def from_api_to_bigquery():

    yester_date = getparam_yesterday_date()

    print(f'<{log_datetime}>: –ù–∞—á–∏–Ω–∞—é –∑–∞–ø—Ä–æ—Å –¥–∞–Ω–Ω—ã—Ö –ø–æ API –∑–∞ –¥–∞—Ç—É {yester_date}')

    InstallsAPIRequest(
                    url=api_url, 
                    headers={'Authorization': api_key}, 
                    api_method='installs', 
                    params={'date': yester_date})

    OrdersAPIRequest(
                    url=api_url, 
                    headers={'Authorization': api_key}, 
                    api_method='orders', 
                    params={'date': yester_date})

    CostsAPIRequest(
                    url=api_url, 
                    headers={'Authorization': api_key}, 
                    api_method='costs', 
                    params={'date': yester_date, 'dimensions': 'location,channel,medium,campaign,keyword,ad_content,ad_group,landing_page'})

    EventsAPIRequest(
                    url=api_url, 
                    headers={'Authorization': api_key}, 
                    api_method='events', 
                    params={'date': yester_date})
    
    create_data_marts(yester_date)

schedule.every().day.at('02:00').do(from_api_to_bigquery)

while True:
    schedule.run_pending()
    time.sleep(3600)

"""
project_id = 'test-task-data-manager'
credentials = service_account.Credentials.from_service_account_file(
    'test-task-data-manager-a8796afc73ae.json')

client = bigquery.Client(project=project_id, credentials=credentials)

data = [
    {"column1": 'value1', "column2": 'value2'},
    {"column1": 'value3', "column2": 'value4'},
    # –î—Ä—É–≥–∏–µ —Å–ª–æ–≤–∞—Ä–∏
]

df = pd.DataFrame(data)

dataset_id = "data_test"
table_id = "data_test_table"

dataset = client.dataset(dataset_id)

if dataset is None:
    print('–°–æ–∑–¥–∞—ë—Ç—Å—è –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç')
    client.create_dataset(dataset)

    table_ref = client.dataset(dataset_id).table(table_id)

    job_config = bigquery.LoadJobConfig(
        schema=[
            bigquery.SchemaField("column1", "STRING"),
            bigquery.SchemaField("column2", "STRING"),
            # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –ø–æ–ª—è –∏ –∏—Ö —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        ],
        # write_disposition="WRITE_TRUNCATE",  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ "WRITE_APPEND", –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        write_disposition="WRITE_APPEND",  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ "WRITE_APPEND", –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    )

    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    job.result()  # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏
else:
    print('–î–∞—Ç–∞—Å–µ—Ç —É–∂–µ –µ—Å—Ç—å')
    table_ref = client.dataset(dataset_id).table(table_id)
    print('–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ —Å–æ–∑–¥–∞–Ω–æ')
    job_config = bigquery.LoadJobConfig(
        schema=[
            bigquery.SchemaField("column1", "STRING"),
            bigquery.SchemaField("column2", "STRING"),
            # –î–æ–±–∞–≤—å—Ç–µ –¥—Ä—É–≥–∏–µ –ø–æ–ª—è –∏ –∏—Ö —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        ],
        # write_disposition="WRITE_TRUNCATE",  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ "WRITE_APPEND", –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
        write_disposition="WRITE_APPEND",  # –ó–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ "WRITE_APPEND", –µ—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å –¥–∞–Ω–Ω—ã–µ
    )
    print('–ó–∞–ø–∏—Å–∏ —Å–æ–∑–¥–∞–Ω—ã')
    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    print('–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ BigQuery')
    job.result()  # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∑–∞–¥–∞—á–∏ –∑–∞–≥—Ä—É–∑–∫–∏
"""

# –ü—Ä–æ–±–ª–µ–º–∞ –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —Å—Ö–µ–º—ã –¥–∞–Ω–Ω—ã—Ö (–ò–ú–ï–ù–ù–û –°–û–ó–î–ê–ù–ò–ò) BigQuery –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç
# –∑–Ω–∞—á–µ–Ω–∏—è None –∫–∞–∫ —á–∏—Å–ª–µ–Ω–Ω—ã–µ NULL –∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö —Å—Ç–æ–ª–±—Ü–∞ –∫–∞–∫ INTEGER (–¥–∞–∂–µ –µ—Å–ª–∏ –±—ã–ª–æ —É–∫–∞–∑–∞–Ω–æ STRING).
# –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ, –¥–∞–Ω–Ω—ã–µ —Ç–∏–ø–∞ str –±–æ–ª—å—à–µ –Ω–µ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ —ç—Ç–∏ —Å—Ç–æ–ª–±—Ü—ã.
# –í –∫–∞—á–µ—Å—Ç–≤–µ —Ä–µ—à–µ–Ω–∏—è –ø—Ä–∏ —Ä–∞–∑–≤—ë—Ä—Ç–∫–µ –¥–∞–Ω–Ω—ã—Ö, –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∑–∞–º–µ–Ω—è—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è None –Ω–∞ str(None), –µ—Å–ª–∏ –≤ –¥–∞–Ω–Ω–æ–º —Å—Ç–æ–ª–±—Ü–µ –æ–∂–∏–¥–∞–µ—Ç—Å—è —Å—Ç—Ä–æ–∫–∞, –∞ –Ω–µ —á–∏–ª–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
# test_data_list = [
#                 {'user_id': 'nPyK3AMVav9ZEOaY', 'event_time': '2023-12-12 00:03:18', 'alpha_2': 'AT', 'alpha_3': 'AUT', 'flag': 'üá¶üáπ', 'name': 'Austria', 'numeric': '040', 'official_name': 'Republic of Austria', 'os': 'iOS', 'brand': 'Apple', 'model': 'iPhone', 'model_number': 14, 'specification': '', 'event_type': 'Search Initiated', 'location': '', 'user_action_detail': '', 'session_number': None, 'localization_id': 'es', 'ga_session_id': None, 'value': Decimal('76.0'), 'state': Decimal('0.0'), 'engagement_time_msec': Decimal('47360.0'), 'current_progress': None, 'event_origin': 'auto', 'place': Decimal('8.0'), 'selection': None, 'analytics_storage': 'Yes', 'browser': None, 'install_store': 'Null', 'transaction_id': None, 'campaign_name': None, 'source': None, 'medium': None, 'term': None, 'context': None, 'gclid': None, 'dclid': None, 'srsltid': None, 'user_is_active': None, 'marketing_id': 'YaAelMIuE0vC'},
#                 {'user_id': 'nPyK3AMVav9ZEOaY', 'event_time': '2023-12-12 00:03:18', 'alpha_2': 'AT', 'alpha_3': 'AUT', 'flag': 'üá¶üáπ', 'name': 'Austria', 'numeric': '040', 'official_name': 'Republic of Austria', 'os': 'iOS', 'brand': 'Apple', 'model': 'iPhone', 'model_number': 14, 'specification': '', 'event_type': 'Search Initiated', 'location': '', 'user_action_detail': '', 'session_number': 'test', 'localization_id': 'es', 'ga_session_id': 'test', 'value': Decimal('76.0'), 'state': Decimal('0.0'), 'engagement_time_msec': Decimal('47360.0'), 'current_progress': 'test', 'event_origin': 'auto', 'place': Decimal('8.0'), 'selection': 'test', 'analytics_storage': 'Yes', 'browser': 'test', 'install_store': 'Null', 'transaction_id': 'test', 'campaign_name': 'test', 'source': 'test', 'medium': 'test', 'term': 'test', 'context': 'test', 'gclid': 'test', 'dclid': 'test', 'srsltid': 'test', 'user_is_active': 'test', 'marketing_id': 'YaAelMIuE0vC'},
#                 ]
# for ind in test_data_list:
#     for field, value in ind.items():
#         print(f"{field}: {value}, {type(value)}")
#     print('===================================')
# test_events_send_bugrequest = EventsBigQueryUploadData(test_data_list)